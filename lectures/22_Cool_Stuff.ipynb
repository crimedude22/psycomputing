{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cool Stuff\n",
    "\n",
    "Below is a collection of random stuff that we didn't get to cover that you may find useful in the future. \n",
    "\n",
    "\n",
    "### Parsing Webpages\n",
    "Sometimes you want to pull information from websites in some ordered way. This is possible because websites are written in HTML, which is a structured, hierarchically-organized format. The best package for doing this is called BeautifulSoup, but when we import it, we use the package `bs4`, which is just the newest version of it. We use the package `requests` to initially open up the webpage so we can load the data into BeautifulSoup. We can then search for particular elements of the webpage using the `find_all` method. This requires you to know a bit of HTML\n",
    "\n",
    "Below is a function that pulls the tweets from a named Twitter user and prints them (just the first few). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString\n",
    "import requests\n",
    "\n",
    "def print_tweets(user):\n",
    "    r = requests.get(\"https://twitter.com/%s\" %user)\n",
    "    html = r.text\n",
    "\n",
    "    soup =  BeautifulSoup(html, 'html.parser') \n",
    "\n",
    "    tweets =  soup.find_all('strong', {'class': 'fullname js-action-profile-name show-popup-with-id'})\n",
    "\n",
    "    for i in range(len(tweets)):\n",
    "        user = tweets[i].contents[0]\n",
    "\n",
    "        action_tag = soup('span', {'class': 'username js-action-profile-name'})\n",
    "        show_name = action_tag[i].contents[1].contents[0]\n",
    "\n",
    "        twit_text = soup('p', {'class': 'js-tweet-text'})\n",
    "\n",
    "        message = \"\"\n",
    "\n",
    "        for nib in twit_text[i]:\n",
    "            if isinstance(nib, NavigableString):\n",
    "                message += nib\n",
    "            else:\n",
    "                message += nib.text\n",
    "\n",
    "        print \"@\"+show_name, message\n",
    "        print \" \"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_tweets('whitehouse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_tweets('justinbieber')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a function that does the same thing, except it displays all the images from a twitter feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "def show_tweet_images(user):\n",
    "    r = requests.get(\"https://twitter.com/%s\" %user)\n",
    "    html = r.text\n",
    "\n",
    "    soup =  BeautifulSoup(html, 'html.parser') \n",
    "\n",
    "    allimg = [img['src'] for img in soup.findAll('img',src=re.compile('http.*media.*.g$'))]\n",
    "\n",
    "    for img in allimg:\n",
    "        print img\n",
    "        display(Image(url=img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_tweet_images('justinbieber')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a function that just does a Google Image search, then grabs a random result and displays it. We can give an optional argument specifying the number of images we want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import random\n",
    "import re\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "def display_google_image(query,num_results=1):\n",
    "    \n",
    "    \n",
    "    for i in range(num_results):\n",
    "    \n",
    "        #make the query in the appropriate format\n",
    "        query= query.lower().split()\n",
    "        query='+'.join(query)\n",
    "\n",
    "        #it only returns 20 images at a time, this chooses a random \"page\" of 20 images (from 1-50)\n",
    "        page = random.randint(1,50) \n",
    "\n",
    "\n",
    "\n",
    "        #pull the info from the webpage\n",
    "        header = {'User-Agent': 'Mozilla/5.0'} \n",
    "\n",
    "        r = requests.get('https://www.google.com/search',\n",
    "                         params={'q': query,'start':page,'source': 'lnms','tbm':'isch'},\n",
    "                         headers=header)\n",
    "\n",
    "\n",
    "        #parse it\n",
    "        soup = BeautifulSoup(r.text,'html')\n",
    "        #find all image urls\n",
    "        images = [a['src'] for a in soup.findAll(\"img\", {\"src\": re.compile(\"gstatic.com\")})]\n",
    "\n",
    "\n",
    "        imgnum = random.randint(0,len(images)-1)\n",
    "\n",
    "\n",
    "        randimg = images[imgnum]\n",
    "\n",
    "#         print \"Search URL: \" +r.url #print the url. \n",
    "#         print \"Page: \"+str(page)\n",
    "#         print \"Image #: \"+str(imgnum)\n",
    "        print \"Image URL: \"+randimg\n",
    "\n",
    "        display(Image(url=randimg,width=250))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we search for our favorite query, \"pug costume\". The only downside is that it only loads the thumbnail image, and not the full-sized one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_google_image(\"pug costume\",5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better Plotting\n",
    "\n",
    "`matplotlib` is great, but clunky. The plots are also not very interactive. There are a couple of packages out there that make it easy to make nice, interactive plots that can be run in the web browser. \n",
    "\n",
    "### Bokeh\n",
    "The older one is called `bokeh`. It can create interactive plots with some basic controls. One thing it can do is produce maps with coordinates overlayed on them. Let's make an interactive version of one of our runs. Watch how you can pan and zoom on the plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "df = DataFrame.from_csv('./datasets/20runs.csv',index_col=False)\n",
    "\n",
    "\n",
    "subset = df[df.user=='gypsydude']\n",
    "subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.io import output_file, show\n",
    "from bokeh.models import GMapPlot, GMapOptions, ColumnDataSource, Line, PanTool, WheelZoomTool,DataRange1d\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "map_options = GMapOptions(lat=subset.latitude.median(), lng=subset.longitude.median(), map_type=\"satellite\",zoom=14)\n",
    "\n",
    "plot = GMapPlot(\n",
    "    x_range=DataRange1d(), y_range=DataRange1d(), map_options=map_options, title=\"GypsyDude's Runs\",plot_width=800,\n",
    "    plot_height=800\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "source = ColumnDataSource(\n",
    "        data=dict(\n",
    "            lat=subset.latitude,\n",
    "            lon=subset.longitude,\n",
    "        )\n",
    "    )\n",
    "\n",
    "circle = Line(x=\"lon\", y=\"lat\", line_width=2.5, line_color=\"red\", line_alpha=0.5)\n",
    "plot.add_glyph(source, circle)\n",
    "\n",
    "plot.add_tools(PanTool(), WheelZoomTool())\n",
    "output_file(\"gmap_plot.html\")\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotly\n",
    "\n",
    "Plotly is newer and fancier. The trick is that it requires you to setup an account, because it's made for creating and sharing plots on the web. The account is free though. I have already created one that you can try from here. Plotly can create all kinds of plots, but here's an example of something you can't to with matplotlib well: 3D surface plots. Cool!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import pandas as pd\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "py.sign_in('psycomputing', 'qoka645e05')\n",
    "\n",
    "\n",
    "init_notebook_mode() # run at the start of every ipython notebook to use plotly.offline\n",
    "                     # this injects the plotly.js source files into the notebook\n",
    "\n",
    "\n",
    "# Read data from a csv\n",
    "z_data = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/api_docs/mt_bruno_elevation.csv')\n",
    "\n",
    "data = [\n",
    "    go.Surface(\n",
    "        z=z_data.as_matrix()\n",
    "    )\n",
    "]\n",
    "layout = go.Layout(\n",
    "    title='Mt Bruno Elevation',\n",
    "    autosize=False,\n",
    "    width=600,\n",
    "    height=600,\n",
    "    margin=dict(\n",
    "        l=65,\n",
    "        r=50,\n",
    "        b=65,\n",
    "        t=90\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='elevations-3d-surface')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursion\n",
    "\n",
    "This is an advanced topic that will take a while to really understand. Recursive functions are ones that operate the same way at many different levels. Remember our image homework, where we created the mirror images of Ernie? Below I have a function that produces the same thing. But, it has a \"level\" argument. When level is 1, then it makes the 4-paneled image. When level is 2, it makes that 4-paneled image, then takes that 4-paneled image and creates mirror images out of *that*, so 16 total images. This can repeat for many levels. Notice that the function has no loops in it. It only has the code for doing level 1, and if level is higher, then *it calls itself*, with level minus 1. Recursion is the closest thing a programmer can produce that feelslike magic. Go ahead and open the \"pattern.jpg\" file from the images folder. That is what you get with level 9 (262,144 Ernies).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load the image first: \n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "im = Image.open('./datasets/ernie.jpg')\n",
    "\n",
    "\n",
    "box = (550,450,900,875)\n",
    "\n",
    "ernie = im.crop(box)\n",
    "ernie.thumbnail((100,100))\n",
    "ernie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#here is the function\n",
    "def mirror_images(img,level=1):\n",
    "    \n",
    "    if level==1:\n",
    "        #blank image to hold 4 of the originals\n",
    "        blank = Image.new('RGB',(img.width*2,img.height*2))\n",
    "        #paste all 4, flipping them so they're symmetrical horizontally and vertically\n",
    "        blank.paste(img,(0,0))\n",
    "        blank.paste(img.transpose(Image.FLIP_LEFT_RIGHT),(img.width,0))\n",
    "        blank.paste(img.transpose(Image.FLIP_TOP_BOTTOM),(0,img.height))\n",
    "        blank.paste(img.transpose(Image.FLIP_LEFT_RIGHT).transpose(Image.FLIP_TOP_BOTTOM),(img.width,img.height))   \n",
    "    else:\n",
    "        img2 = mirror_images(img,1)\n",
    "        blank = mirror_images(img2,level-1)\n",
    "    return(blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#level 1\n",
    "mirror_images(ernie,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#level 2\n",
    "\n",
    "mirror_images(ernie,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#level 5\n",
    "mirror_images(ernie,5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
