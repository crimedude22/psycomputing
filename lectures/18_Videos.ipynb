{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Videos\n",
    "\n",
    "Python can also deal with video files. The most convenient package for this is `moviepy`. This will show you some of the basics of what it can do. \n",
    "\n",
    "First we import the `moviepy` package and load in a video file. We use the `VideoFileClip` funciton and provide a path to a video file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "\n",
    "video = VideoFileClip('./datasets/dancing_duo.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like images, we can access some basic properties of our video clip using the dot notation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print video.duration #duration in seconds\n",
    "print video.size #size in pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, there isn't a reliable way to play the video in the Jupyter notebook. But, we can take a single frame from the video and display it. We use the `get_frame` function to grab a still image from the movie. We provide a tuple indicating the timepoint in the form (hours,minutes,seconds). To show the image, we use the `imshow` function form `matplotlib`. Remember, we don't have to call it `frame`, we can call it whatever we want, it's a variable. \n",
    "\n",
    "Here we grab a frame from 6 seconds into the video and plot the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "frame = video.get_frame(t=(0,0,6)) #grab frame at 6 seconds\n",
    "print type(frame) #numpy array\n",
    "print frame.shape #height x width x RGB\n",
    "\n",
    "#plot with matplotlib\n",
    "plt.imshow(frame)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#here we grab the frame at 6.5 seconds\n",
    "frame = video.get_frame(t=(0,0,6.5))\n",
    "\n",
    "plt.imshow(frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a performance form [Star Search](https://en.wikipedia.org/wiki/Star_Search), a show from the 80's and 90's that basically inspired shows like American Idol and Amerca's Got Talent. People would either sing or dance and compete for money and fame. A good friend of mine used to record the episodes when she was a kid and held on to these gems for the world to enjoy.  \n",
    "\n",
    "<img src=\"http://images.videolan.org/images/VLC-IconSmall.png\", align=\"left\"></img>You can open the file outside of Jupyter to see the whole thing. Note: sometimes the default video players for Windows or Mac will not play the audio correctly. That is because they're picky about the particular video formats that they will play. I recommend that everyone install the program [VLC](http://www.videolan.org/vlc/) to play the videos. This is already installed on the lab computers. It works great for Windows or Mac and plays any type of video or audio file imaginable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating subclips\n",
    "\n",
    "Let's create a shorter clip of this overall video. We can do this using the `subclip` method. You provide the arguments `t_start` and `t_end` as tuples, just like the example above. The function will copy the part of the video that falls within those timepoints and produce a new video clip. Below we grab the video from 4.5 to 6.5 seconds. Note that the duration of `subclip` is only 2 seconds.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subclip = video.subclip(t_start=(0,0,4.5),t_end=(0,0,6.5)) #grab a clip from 6 to 7.5 seconds\n",
    "\n",
    "subclip.duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving video files\n",
    "\n",
    "Now let's save this subclip as its own video file. We do this using the `to_videofile` method. We provide a filename with the appropriate file extension. One of the most common is `.mp4`, so we use that for this example. Run the cell below, then open the `subclip.mp4` file to see what you get. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subclip.to_videofile('subclip.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GIFs!\n",
    "\n",
    "We can also save the clip as an animated GIF file. Remember, GIFs can't be too long, so don't try to save a 10 minute video or anything. Don't do longer than a few seconds. We use the `to_gif` method for this. Once we save it as a file, then we can display it in the notebook nicely using the `Image` function from `IPython.display`. An annoying quirk of this function, though, is that you need to say `url='subclip.gif'` instead of just `subclip.gif`. Otherwise, it says it cannot display it. \n",
    "\n",
    "Note: you can click Cell->Current Output-> Clear to erase the image. It can get distracting if you're looking at it for a while!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subclip.to_gif('subclip.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(url='subclip.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Text to Videos\n",
    "\n",
    "We can overlay text onto videos using the `TextClip` function. First we create just a video with text on it and save as a file to illustrate. We can change the font size, the color, and the position. We can set the duration to whatever we want. Let's say 5 seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a text clip. You can customize the font, color, etc.\n",
    "txt_clip = TextClip(\"Time to Dance!!\",fontsize=70,color='white')\n",
    "\n",
    "# Say that you want it to appear 10s at the center of the screen\n",
    "txt_clip = txt_clip.set_pos('center') #or left,right,top,bottom or ('left','top')\n",
    "txt_clip = txt_clip.set_duration(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write it to a video file to view it. Because we're creating this video from scratch, we need to specify the frames per second (fps). Check out justtext.mp4 outside of jupyter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txt_clip.to_videofile('justtext.mp4',fps=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too exciting. What we want is to overlay this text on our video. Let's create a subclip of our video that's about 15 seconds, then put our text on it. We can layer video clips using `CompositeVideoClip`. Here we also change the start time of `txt_clip` so the text doesn't stay on the whole time, we will have it start at the 3 second mark. We also provide an ending time with `set_end`. If we don't do this, the text just stays on for the duration of the video. \n",
    "\n",
    "We also create another text clip to appear afterward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subclip = video.subclip(t_start=(0,0,45),t_end=(0,1,1))\n",
    "\n",
    "txt_clip = txt_clip.set_duration(subclip.duration)\n",
    "txt_clip = txt_clip.set_start((0,0,3))\n",
    "txt_clip = txt_clip.set_end((0,0,6))\n",
    "\n",
    "#let's make another text clip!\n",
    "txt_clip2 = TextClip(\"Dance Again!\",fontsize=45,color='white')\n",
    "\n",
    "txt_clip2 = txt_clip2.set_pos(('left','top')) #display at the top-left\n",
    "txt_clip2 = txt_clip2.set_duration(3)\n",
    "txt_clip2 = txt_clip2.set_start((0,0,7)) #start at 7 s\n",
    "txt_clip2 = txt_clip2.set_end((0,0,10)) #end at 10s\n",
    "\n",
    "\n",
    "video_w_text = CompositeVideoClip([subclip,txt_clip,txt_clip2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_w_text.to_videofile('video_w_text.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting video into many images\n",
    "\n",
    "You can use the `write_images_sequence` function to take a video and create an image from each frame. Here we grab the same clip from 4.5 to 6.5 seconds. This creates a lot of files, so we create a subfolder called \"frames\" to save them in (do this outside of Python). `write_images_sequence` takes 1 primary argument: the format of the image file names. Here we put a placeholder \"%03d\". This is where the frame number will go. Because we say \"03\" it will make the frame number as a 3-digit number (001,002,0003...). If we did \"%06d\" it would do 6 digits (000001,000002,000003...). \n",
    "\n",
    "This function is supposed to produce other file types like .jpg, but this did not work for the particular video file. So we save them as .png files. After you run the cell, check your \"frames\" folder and see the images. This function also produces a list full of the file names, which we could use if we wanted by saying \n",
    "``` python\n",
    "filelist = shortclip.write_images_sequence('./frames/frame%03d.png')\n",
    "```\n",
    "\n",
    "Otherwise, it just spits it out into the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shortclip = video.subclip(t_start=(0,0,4.5),t_end=(0,0,6.5)) #grab a clip from 6 to 7.5 seconds\n",
    "\n",
    "shortclip.write_images_sequence('./frames/frame%03d.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining images into a video\n",
    "\n",
    "Now let's do the reverse. We'll get a list of image files (the ones we just created) and combine them into a movie. First we move to the folder where the frames are held, and use `glob` to get all the `.png` files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "os.chdir('frames')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allframes = glob('*.png')\n",
    "print allframes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use the `ImageSequenceClip` function to create a movie from a sequence of image files, which we called `allframes` above. We specify the frames per second when we do this. Then we can write the video file to see if we recreated the original clip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clip = ImageSequenceClip(allframes, fps=30)\n",
    "clip.to_videofile('combined_images.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Animations\n",
    "\n",
    "You can create pretty fancy animations in Python using the `gizeh` package to make drawings, and `moviepy` to combine them. They're a bit too advanced for the class, but you should check them out here: <http://zulko.github.io/blog/2014/09/20/vector-animations-with-python/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing audio tracks from video files\n",
    "\n",
    "First, let's grab just the audio from our original video and save it as a MP3 file. We just use `AudioFileClip` instead of `VideoFileClip` and it will load only the audio from our file. First we move back to our original folder by going 1 level up, using '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "justaudio = AudioFileClip('dancing_duo.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR, if you have the file already loaded as a video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "justaudio = video.audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the audio clip as an MP3 like so: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "justaudio.to_audiofile('song.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the audio track of a file just as easily using `set_audio`. Let's make a little video from one of our pug pictures, then make part of song.mp3 as the audio track. First we create a 15 second clip from the file using `ImageClip`, then the `set_duration` method. Then we grab a 15 second portion of our audio, and set that as the audio track. Then we write the result to a file. \n",
    "\n",
    "Note: the more fun thing to do is combine multiple pug images into a video. In order for this to work, all images need to be the same dimensions. We can do this with PIL but it is extra work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pugvid = ImageClip('pug.jpg').set_duration(15) #load the image, make into a 15 second video\n",
    "\n",
    "audio_clip = justaudio.subclip(t_start=(0,0,2),t_end=(0,0,17))\n",
    "\n",
    "pugvid = pugvid.set_audio(audio_clip)\n",
    "\n",
    "pugvid.to_videofile('pugs.mp4',fps=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
